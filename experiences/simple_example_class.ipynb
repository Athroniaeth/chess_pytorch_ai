{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import polars\n",
    "\n",
    "max_length = 300_000\n",
    "dataframe = polars.read_csv('../data/chessData.csv')\n",
    "dataframe = dataframe.sample(shuffle=True, seed=42, n=max_length)\n",
    "print(dataframe.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy\n",
    "from typing import Generator, Tuple\n",
    "import itertools\n",
    "import chess\n",
    "\n",
    "ProductPiece = Tuple[chess.PieceType, chess.Color]\n",
    "\n",
    "\n",
    "def generator_pieces() -> Generator[ProductPiece, None, None]:\n",
    "    return itertools.product(chess.PIECE_TYPES, chess.COLORS)\n",
    "\n",
    "\n",
    "def tokenize_fen(fen: str):\n",
    "    board = chess.Board(fen=fen)\n",
    "    board_array = numpy.array([], ndmin=2)\n",
    "\n",
    "    for piece_type, color in generator_pieces():\n",
    "        # Obtiens les pièces du plateau\n",
    "        square_set = board.pieces(piece_type, color)\n",
    "\n",
    "        # Crée un masque (numpy va inverser les axes, donc on utilise mirror)\n",
    "        mask = square_set.mirror().tolist()\n",
    "\n",
    "        # Convertit le masque en tableau numpy et en one-hot\n",
    "        piece_array = numpy.array(mask).astype(int)\n",
    "\n",
    "        # Ajoute le tableau de pièces au tableau de plateau\n",
    "        board_array = numpy.append(board_array, piece_array)\n",
    "\n",
    "    board_array = board_array.astype(numpy.uint8)\n",
    "    return tuple(board_array)"
   ],
   "id": "bfdafbaf4a4a24fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "start_pos = \"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\"\n",
    "result = tokenize_fen(start_pos)\n",
    "print(len(result))\n",
    "print(sum(result))\n",
    "\n",
    "print(sum(result[:64]))  # white pawn\n",
    "print(sum(result[64:128]))  # black pawn\n",
    "\n",
    "print(sum(result[-128:-64]))  # white king\n",
    "print(sum(result[-64:]))  # black king"
   ],
   "id": "756c366ced9e6cea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fen_column = \"FEN\"\n",
    "score_column = \"Evaluation\"\n",
    "\n",
    "expression = polars.col(fen_column).map_elements(tokenize_fen, return_dtype=polars.List(polars.UInt8))\n",
    "preprocess_df = dataframe.with_columns(expression)\n",
    "\n",
    "# Filtrer les lignes où la colonne ne contient pas '#-'\n",
    "filtered_df = preprocess_df.filter(~polars.col(score_column).str.contains('#-'))\n",
    "filtered_df = filtered_df.filter(~polars.col(score_column).str.contains('#+'))\n",
    "\n",
    "# Convertir la colonne en entier\n",
    "filtered_df = filtered_df.with_columns(polars.col(score_column).cast(polars.Int16))\n",
    "\n",
    "min_value = filtered_df[score_column].min()\n",
    "max_value = filtered_df[score_column].max()\n",
    "\n",
    "print(f\"Min value : '{min_value:.2f}  -  Max value : {max_value:.2f}\")\n",
    "\n",
    "# Le dataset contient '#+0' ou '#-0' dans score quand il y'a un mat, on remplace par le maximum de la couleur\n",
    "expression = (\n",
    "    polars\n",
    "    .when(polars.col(score_column).str.contains('#+'))\n",
    "    .then(polars.lit(f'{max_value}'))\n",
    "\n",
    "    .when(polars.col(score_column).str.contains('#-'))\n",
    "    .then(polars.lit(f'{min_value}'))\n",
    "\n",
    "    .otherwise(polars.col(score_column))\n",
    "    .alias(score_column))\n",
    "\n",
    "preprocess_df = preprocess_df.with_columns(expression)\n",
    "\n",
    "# Convertit le dtype string de 'score' en dtype float\n",
    "expression = polars.col(score_column).cast(polars.Int16)\n",
    "preprocess_df = preprocess_df.with_columns(expression)\n",
    "\n",
    "# Ré-équilibre le dataset \n",
    "expression = polars.col(score_column).ne(0)\n",
    "preprocess_df = preprocess_df.filter(expression)\n",
    "\n",
    "# Si une valeur dépasse 2000 ou -2000, le remplace par 2000 ou -2000\n",
    "# expression = polars.col(score_column).clip(-2000, 2000)\n",
    "# preprocess_df = preprocess_df.with_columns(expression)\n",
    "\n",
    "conditions = (\n",
    "    polars.when(polars.col(score_column) >= 200).then(6)\n",
    "    .when((polars.col(score_column) >= 100) & (polars.col(score_column) < 200)).then(5)\n",
    "    .when((polars.col(score_column) >= 50) & (polars.col(score_column) < 100)).then(4)\n",
    "    .when((polars.col(score_column) >= -50) & (polars.col(score_column) < 50)).then(3)\n",
    "    .when((polars.col(score_column) <= -50) & (polars.col(score_column) > -100)).then(2)\n",
    "    .when((polars.col(score_column) <= -100) & (polars.col(score_column) > -200)).then(1)\n",
    "    .when((polars.col(score_column) <= -200)).then(0)\n",
    ")\n",
    "# Ajouter la colonne de classification au DataFrame\n",
    "preprocess_df = preprocess_df.with_columns(conditions.alias(\"classification\"))\n",
    "\n",
    "# Renomme les colonnes en 'fen' et 'score'\n",
    "preprocess_df = preprocess_df.rename({fen_column: 'fen', score_column: 'score'})"
   ],
   "id": "a6cb2b783923870a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(preprocess_df.head())",
   "id": "5c39ebc52ff375a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, preprocess_df: polars.DataFrame):\n",
    "        self.dataframe = preprocess_df\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        # Récupère la FEN et le score\n",
    "        array = self.dataframe['fen'][index]\n",
    "        _classification = self.dataframe['classification'][index]\n",
    "        classification = [0 for i in range(7)]\n",
    "        classification[_classification] = 1\n",
    "\n",
    "        # Convertit le tableau numpy en tenseur PyTorch\n",
    "        tensor_array = torch.tensor(array, dtype=torch.float32)\n",
    "        tensor_classification = torch.tensor(classification, dtype=torch.float32)\n",
    "\n",
    "        return tensor_array, tensor_classification\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def hist_score(self, bins: int = 51):\n",
    "        \"\"\"\n",
    "        Affiche un histogramme de la colonne 'score'.\n",
    "\n",
    "        Notes:\n",
    "            Incrémente bins de 1 si celui-ci est pair, cela permet d'afficher le nombre de\n",
    "            zeros dans la colonne 'score'. En impair, nous n'avons que pour > 0 ou < 0.\n",
    "\n",
    "        Args:\n",
    "            bins (int): Nombre de \"bacs\" pour l'histogramme. Defaults to 51.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Si le nombre de bacs est pair, on l'incrémente de 1\n",
    "        bins = bins + 1 if bins % 2 == 0 else bins\n",
    "\n",
    "        # Créer un histogramme de la colonne 'score'\n",
    "        plt.hist(self.dataframe['classification'], bins=bins)\n",
    "\n",
    "        # Ajouter des étiquettes et un titre\n",
    "        plt.xlabel('Valeur')\n",
    "        plt.ylabel('Fréquence')\n",
    "        plt.title('Distribution de la colonne \"score\"')\n",
    "\n",
    "        # Afficher le graphique\n",
    "        plt.show()"
   ],
   "id": "e83da124cbb95bc5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class ChessModel(nn.Module):\n",
    "    def __init__(self, input_size: int = 768):\n",
    "        super(ChessModel, self).__init__()\n",
    "        self.linear_1 = nn.Linear(input_size, 2048)\n",
    "        self.linear_2 = nn.Linear(2048, 1024)\n",
    "        self.linear_3 = nn.Linear(1024, 512)\n",
    "        self.linear_4 = nn.Linear(512, 256)\n",
    "        self.linear_5 = nn.Linear(256, 7)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        _x = self.relu(self.linear_1(x))\n",
    "        _x = self.dropout(_x)\n",
    "        _x = self.relu(self.linear_2(_x))\n",
    "        _x = self.dropout(_x)\n",
    "        _x = self.relu(self.linear_3(_x))\n",
    "        _x = self.dropout(_x)\n",
    "        _x = self.relu(self.linear_4(_x))\n",
    "        _x = self.dropout(_x)\n",
    "        _x = self.softmax(self.linear_5(_x))\n",
    "        return _x\n",
    "\n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        return next(self.parameters()).device"
   ],
   "id": "2be33ecd57a472cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torchmetrics\n",
    "from typing import Literal\n",
    "from src.dataset import split_dataset\n",
    "\n",
    "# Autres paramètres\n",
    "device: Literal['cpu', 'cuda'] = 'cuda'\n",
    "\n",
    "# Paramètres du dataset\n",
    "batch_size: int = 256\n",
    "random_seed: int = 42\n",
    "ratio_tests: float = 0.2\n",
    "ratio_validation: float = 0.2\n",
    "\n",
    "# Paramètres du modèle (apprentissage)\n",
    "num_epochs: int = 100\n",
    "lr: float = 1e-3\n",
    "\n",
    "# Paramètres du scheduler_lr (apprentissage)\n",
    "start_factor: float = 1.0\n",
    "end_factor: float = 0.01\n",
    "total_iters: int = 20\n",
    "\n",
    "metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=7, top_k=2)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "id": "8103554c4f963a19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = ChessModel()\n",
    "dataset = ChessDataset(preprocess_df=preprocess_df)\n",
    "dataset.hist_score(bins=201)\n",
    "print(preprocess_df.get_column('classification').value_counts().sort(\"count\"))"
   ],
   "id": "24e3abe06562d7aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import logging\n",
    "import statistics\n",
    "from typing import Literal, Type\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import LRScheduler, LinearLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Metric, MeanAbsoluteError\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src import MODEL_PATH\n",
    "\n",
    "\n",
    "def train_model(\n",
    "        model: nn.Module,\n",
    "\n",
    "        train_loader: DataLoader,\n",
    "        tests_loader: DataLoader,\n",
    "        validation_loader: DataLoader,\n",
    "\n",
    "        num_epochs: int = 20,\n",
    "        device: Literal['cpu', 'cuda'] = 'cuda',\n",
    "\n",
    "        optimizer: Type[Optimizer] = torch.optim.Adam,\n",
    "        metric: Metric = MeanAbsoluteError,\n",
    "        criterion: _Loss = nn.MSELoss,\n",
    "\n",
    "        lr: float = 1e-4,\n",
    "\n",
    "        scheduler: Type[LRScheduler] = LinearLR,\n",
    "        start_factor: float = 1.0,\n",
    "        end_factor: float = 1e-6,\n",
    "        total_iters: int = 10\n",
    "):\n",
    "    train_score, tests_score, validation_score = 0, 0, 0\n",
    "\n",
    "    # Crée le modèle\n",
    "    model = model.to('cpu')\n",
    "    logging.info(f\"Device: {model.device}\")\n",
    "\n",
    "    # noinspection PyArgumentList\n",
    "    optimizer = optimizer(model.parameters(), lr=lr)\n",
    "\n",
    "    # noinspection PyArgumentList\n",
    "    scheduler = scheduler(\n",
    "        optimizer=optimizer,\n",
    "        start_factor=start_factor,\n",
    "        end_factor=end_factor,\n",
    "        total_iters=total_iters\n",
    "    )\n",
    "\n",
    "    metric_name = metric.__class__.__name__\n",
    "\n",
    "    # Entraîne le modèle\n",
    "    for epoch in range(num_epochs):\n",
    "        pbar = tqdm(train_loader, total=len(train_loader), leave=False)\n",
    "\n",
    "        list_loss = []\n",
    "        for x, y in pbar:\n",
    "            x = x.to(device='cpu')\n",
    "            y = y.to(device='cpu')  # Met 'y' en batch_size de 1\n",
    "\n",
    "            predictions = model(x).to(device='cpu')\n",
    "\n",
    "            loss = criterion(predictions, y).to(device='cpu')\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.set_description(f\"Epochs: {epoch + 1}/{num_epochs}  -  Loss: {loss.item():.1e}\")\n",
    "            list_loss.append(loss.item())\n",
    "\n",
    "        scheduler.step()\n",
    "        # afficher sous forme 1e-3, 2e-3, 3e-3, etc.\n",
    "        tqdm.write(f\"Learning rate: {scheduler.get_last_lr()[0]:.1e}\")\n",
    "        train_score = check_accuracy(train_loader, model, metric)\n",
    "        tests_score = check_accuracy(tests_loader, model, metric)\n",
    "\n",
    "        avg_loss = statistics.mean(list_loss)\n",
    "        tqdm.write(f\"Epochs: {epoch + 1}/{num_epochs}  -  Loss: {avg_loss:.1e}  -  Train ({metric_name}): {train_score:.2f}  -  Tests ({metric_name}) : {tests_score:.2f}\")\n",
    "\n",
    "        # Sauvegarde le modèle\n",
    "        path = MODEL_PATH / f\"model_{epoch + 1}.pth\"\n",
    "        torch.save(model.state_dict(), path)\n",
    "\n",
    "    # Affiche les derniers scores sur tout le dataset (tout les batchs)\n",
    "    validation_score = check_accuracy(validation_loader, model, metric)\n",
    "\n",
    "    logging.info(f\"[Score global train] : {train_score:.2f}%\")\n",
    "    logging.info(f\"[Score global tests] : {tests_score:.2f}%\")\n",
    "    logging.info(f\"[Score global validation] : {validation_score:.2f}%\")\n",
    "\n",
    "\n",
    "def check_accuracy(\n",
    "        loader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        metrics: Metric,\n",
    "):\n",
    "    \"\"\"\n",
    "    Fonction pour calculer la précision du modèle\n",
    "    \"\"\"\n",
    "    list_accuracy = []\n",
    "\n",
    "    # Récupère le device du modèle\n",
    "    device = model.device\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)  # Met 'y' en batch_size de 1\n",
    "\n",
    "            predictions = model(x).to(device=device)\n",
    "\n",
    "            accuracy = metrics(preds=predictions, target=y)\n",
    "            list_accuracy.append(accuracy.item())\n",
    "\n",
    "    global_accuracy = statistics.mean(list_accuracy)\n",
    "    return global_accuracy\n",
    "\n",
    "\n",
    "def _calcul_accuracy(\n",
    "        predictions: torch.Tensor,\n",
    "        labels: torch.Tensor,\n",
    "        tolerance: float = 1e-2):\n",
    "    # Calculer le ratio entre les prédictions et les valeurs réelles\n",
    "    ratio = predictions / labels\n",
    "\n",
    "    # S'assurer que les ratios sont toujours >= 1\n",
    "    mask = ratio < 1\n",
    "    ratio[mask] = 1 / ratio[mask]\n",
    "\n",
    "    # Vérifier si les prédictions sont dans la tolérance\n",
    "    correct = (ratio <= (1 + tolerance)).sum().item()\n",
    "    total = predictions.size(0)\n",
    "\n",
    "    return correct, total\n"
   ],
   "id": "17ac2e2e1bf3ddd3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T12:53:51.866443Z",
     "start_time": "2024-06-17T12:53:49.507005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "list_loaders = split_dataset(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle_dataset=False,\n",
    "    random_seed=random_seed,\n",
    "    ratio_tests=ratio_tests,\n",
    "    ratio_validation=ratio_validation\n",
    ")\n",
    "\n",
    "train_loader, tests_loader, validation_loader = list_loaders\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "model = model.to('cpu')\n",
    "\n",
    "\n",
    "train_model(\n",
    "    device='cuda',\n",
    "\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    tests_loader=tests_loader,\n",
    "    validation_loader=validation_loader,\n",
    "\n",
    "    num_epochs=num_epochs,\n",
    "    lr=lr,\n",
    "\n",
    "    start_factor=start_factor,\n",
    "    end_factor=end_factor,\n",
    "    total_iters=total_iters,\n",
    "\n",
    "    metric=metric,\n",
    "    criterion=criterion,\n",
    ")"
   ],
   "id": "b0199cdda968b447",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                                                 \r\n",
      "Epochs: 1/100  -  Loss: 1.7e+00:   0%|          | 0/635 [00:00<?, ?it/s]\u001B[A\n",
      "Epochs: 1/100  -  Loss: 1.7e+00:   0%|          | 1/635 [00:00<08:24,  1.26it/s]\u001B[A\n",
      "Epochs: 1/100  -  Loss: 1.8e+00:   0%|          | 1/635 [00:00<08:24,  1.26it/s]\u001B[A\n",
      "Epochs: 1/100  -  Loss: 1.8e+00:   0%|          | 2/635 [00:00<04:34,  2.30it/s]\u001B[A\n",
      "Epochs: 1/100  -  Loss: 1.7e+00:   0%|          | 2/635 [00:01<04:34,  2.30it/s]\u001B[A\n",
      "Epochs: 1/100  -  Loss: 1.7e+00:   0%|          | 3/635 [00:01<03:20,  3.15it/s]\u001B[A\n",
      "Epochs: 1/100  -  Loss: 1.7e+00:   0%|          | 3/635 [00:01<03:20,  3.15it/s]\u001B[A\n",
      "Epochs: 1/100  -  Loss: 1.7e+00:   1%|          | 4/635 [00:01<02:45,  3.80it/s]\u001B[A\n",
      "Epochs: 1/100  -  Loss: 1.7e+00:   1%|          | 4/635 [00:01<02:45,  3.80it/s]\u001B[A\n",
      "Epochs: 1/100  -  Loss: 1.7e+00:   1%|          | 5/635 [00:01<02:25,  4.33it/s]\u001B[A\n",
      "Epochs: 1/100  -  Loss: 1.7e+00:   1%|          | 5/635 [00:01<02:25,  4.33it/s]\u001B[A\n",
      "Epochs: 1/100  -  Loss: 1.7e+00:   1%|          | 6/635 [00:01<02:13,  4.70it/s]\u001B[A\n",
      "Epochs: 1/100  -  Loss: 1.8e+00:   1%|          | 6/635 [00:01<02:13,  4.70it/s]\u001B[A\n",
      "Epochs: 1/100  -  Loss: 1.8e+00:   1%|          | 7/635 [00:01<02:06,  4.97it/s]\u001B[A\n",
      "                                                                                \u001B[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[67], line 18\u001B[0m\n\u001B[0;32m     14\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCUDA_LAUNCH_BLOCKING\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     15\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 18\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcuda\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \n\u001B[0;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtests_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtests_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     25\u001B[0m \n\u001B[0;32m     26\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     27\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     28\u001B[0m \n\u001B[0;32m     29\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstart_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstart_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     30\u001B[0m \u001B[43m    \u001B[49m\u001B[43mend_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mend_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     31\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtotal_iters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_iters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     32\u001B[0m \n\u001B[0;32m     33\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     35\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[64], line 62\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, train_loader, tests_loader, validation_loader, num_epochs, device, optimizer, metric, criterion, lr, scheduler, start_factor, end_factor, total_iters)\u001B[0m\n\u001B[0;32m     59\u001B[0m pbar \u001B[38;5;241m=\u001B[39m tqdm(train_loader, total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(train_loader), leave\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m     61\u001B[0m list_loss \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m---> 62\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpbar\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m     63\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcpu\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     64\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcpu\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Met 'y' en batch_size de 1\u001B[39;49;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\chess_pytorch_ai\\Lib\\site-packages\\tqdm\\std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1181\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m   1182\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\n\u001B[0;32m   1183\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Update and possibly print the progressbar.\u001B[39;49;00m\n\u001B[0;32m   1184\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;49;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\chess_pytorch_ai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\chess_pytorch_ai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\chess_pytorch_ai\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\chess_pytorch_ai\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Cell \u001B[1;32mIn[22], line 18\u001B[0m, in \u001B[0;36mChessDataset.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m     15\u001B[0m classification[_classification] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Convertit le tableau numpy en tenseur PyTorch\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m tensor_array \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m tensor_classification \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(classification, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m tensor_array, tensor_classification\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src import MODEL_PATH\n",
    "\n",
    "path = MODEL_PATH / 'model_33.pth'\n",
    "dict_model = torch.load(path, map_location='cpu')\n",
    "model = ChessModel().cpu()\n",
    "model.load_state_dict(dict_model)\n",
    "\n",
    "\n",
    "def analys_model(fen: str):\n",
    "    fen_array = tokenize_fen(fen)\n",
    "    fen_tensor = torch.tensor(fen_array, dtype=torch.float32).view(1, -1)\n",
    "    prediction = model(fen_tensor).item()\n",
    "\n",
    "    print(f\"Prédiction du modèle: {prediction:.2f}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "list_fen = [\n",
    "    \"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\",  # Position de base\n",
    "    \"r1bqkb1r/pppp1ppp/2n2n2/4p2Q/2B1P3/8/PPPP1PPP/RNB1K1NR w KQkq - 4 4\",  # Mat berger, Mat en 1 pour blanc\n",
    "    \"4k3/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQ - 0 1\",  # Noir n'ont qu'un roi\n",
    "    \"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/4K3 w kq - 0 1\",  # Blanc n'ont qu'un roi\n",
    "    \"r3rbk1/p4ppp/8/2Nqp3/1p1P2b1/1P3N2/P2P1PPP/2RQR1K1 w - - 1 21\"  # Position égale éloignée GMI (reputé légèrement favorable noir)\n",
    "]\n",
    "\n",
    "for fen in list_fen:\n",
    "    analys_model(fen)"
   ],
   "id": "576ca51824bc377d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "54f2a2c5b1a8e145",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
