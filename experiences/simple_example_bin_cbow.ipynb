{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-22T08:31:07.106321Z",
     "start_time": "2024-06-22T08:31:06.533402Z"
    }
   },
   "source": [
    "import polars\n",
    "\n",
    "max_length = 100_0\n",
    "dataframe = polars.read_csv('../data/chessData.csv')\n",
    "dataframe = dataframe.sample(shuffle=True, seed=42, n=max_length)\n",
    "print(dataframe.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 2)\n",
      "┌─────────────────────────────────┬────────────┐\n",
      "│ FEN                             ┆ Evaluation │\n",
      "│ ---                             ┆ ---        │\n",
      "│ str                             ┆ str        │\n",
      "╞═════════════════════════════════╪════════════╡\n",
      "│ r1bq2k1/1p3pbp/p2p1np1/2pPr3/P… ┆ +57        │\n",
      "│ R5k1/2nbqpp1/3b1n1p/2pPp3/2P1P… ┆ +82        │\n",
      "│ rqr3k1/3npp2/3p2p1/1N1P3p/P1pR… ┆ +116       │\n",
      "│ 8/5pp1/k5p1/1pK5/8/7P/5PP1/8 w… ┆ -317       │\n",
      "│ 3r2k1/5p1p/1RN1p3/5nP1/1p6/2b1… ┆ +46        │\n",
      "└─────────────────────────────────┴────────────┘\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T08:31:07.113836Z",
     "start_time": "2024-06-22T08:31:07.107331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy\n",
    "from typing import Generator, Tuple\n",
    "import itertools\n",
    "import chess\n",
    "\n",
    "ProductPiece = Tuple[chess.PieceType, chess.Color]\n",
    "\n",
    "\n",
    "def generator_pieces() -> Generator[ProductPiece, None, None]:\n",
    "    return itertools.product(chess.PIECE_TYPES, chess.COLORS)\n",
    "\n",
    "\n",
    "def tokenize_fen(fen: str):\n",
    "    board = chess.Board(fen=fen)\n",
    "    \n",
    "    # Pour chaque case, récupèrer la pièce, donner un indice entre 1-12 (13 si vide)\n",
    "    # 1-6 : Pion, Cavalier, Fou, Tour, Reine, Roi (blanc)\n",
    "    # 7-12 : Pion, Cavalier, Fou, Tour, Reine, Roi (noir)\n",
    "    # 13 : Case vide\n",
    "    board_array = numpy.array([])\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece is None:\n",
    "            board_array = numpy.append(board_array, 12)\n",
    "        else:\n",
    "            piece_type = piece.piece_type\n",
    "            color = piece.color\n",
    "            index = list(generator_pieces()).index((piece_type, color))\n",
    "            board_array = numpy.append(board_array, index)\n",
    "            \n",
    "    board_array = board_array.astype(numpy.uint8)\n",
    "    return tuple(board_array)"
   ],
   "id": "bfdafbaf4a4a24fd",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T08:31:07.119936Z",
     "start_time": "2024-06-22T08:31:07.114863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_pos = \"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\"\n",
    "result = tokenize_fen(start_pos)\n",
    "print(len(result))\n",
    "print(sum(result))\n",
    "\n",
    "print(sum(result[:64]))  # white pawn\n",
    "print(sum(result[64:128]))  # black pawn\n",
    "\n",
    "print(sum(result[-128:-64]))  # white king\n",
    "print(sum(result[-64:]))  # black king\n",
    "\n",
    "print(result)"
   ],
   "id": "756c366ced9e6cea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "484\n",
      "484\n",
      "0\n",
      "0\n",
      "484\n",
      "(6, 2, 4, 8, 10, 4, 2, 6, 0, 0, 0, 0, 0, 0, 0, 0, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 1, 1, 1, 1, 1, 1, 1, 1, 7, 3, 5, 9, 11, 5, 3, 7)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T08:31:07.493476Z",
     "start_time": "2024-06-22T08:31:07.121947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fen_column = \"FEN\"\n",
    "score_column = \"Evaluation\"\n",
    "\n",
    "expression = polars.col(fen_column).map_elements(tokenize_fen, return_dtype=polars.List(polars.UInt8))\n",
    "preprocess_df = dataframe.with_columns(expression)\n",
    "\n",
    "# Filtrer les lignes où la colonne ne contient pas '#-'\n",
    "filtered_df = preprocess_df.filter(~polars.col(score_column).str.contains('#-'))\n",
    "filtered_df = filtered_df.filter(~polars.col(score_column).str.contains('#+'))\n",
    "\n",
    "# Convertir la colonne en entier\n",
    "filtered_df = filtered_df.with_columns(polars.col(score_column).cast(polars.Int16))\n",
    "\n",
    "min_value = filtered_df[score_column].min()\n",
    "max_value = filtered_df[score_column].max()\n",
    "\n",
    "print(f\"Min value : '{min_value:.2f}  -  Max value : {max_value:.2f}\")\n",
    "\n",
    "# Le dataset contient '#+0' ou '#-0' dans score quand il y'a un mat, on remplace par le maximum de la couleur\n",
    "expression = (\n",
    "    polars\n",
    "    .when(polars.col(score_column).str.contains('#+'))\n",
    "    .then(polars.lit(f'{max_value}'))\n",
    "\n",
    "    .when(polars.col(score_column).str.contains('#-'))\n",
    "    .then(polars.lit(f'{min_value}'))\n",
    "\n",
    "    .otherwise(polars.col(score_column))\n",
    "    .alias(score_column))\n",
    "\n",
    "preprocess_df = preprocess_df.with_columns(expression)\n",
    "\n",
    "# Convertit le dtype string de 'score' en dtype float\n",
    "expression = polars.col(score_column).cast(polars.Int16)\n",
    "preprocess_df = preprocess_df.with_columns(expression)\n",
    "\n",
    "# Ré-équilibre le dataset \n",
    "expression = polars.col(score_column).ne(0)\n",
    "preprocess_df = preprocess_df.filter(expression)\n",
    "\n",
    "# Si une valeur dépasse 2000 ou -2000, le remplace par 2000 ou -2000\n",
    "# expression = polars.col(score_column).clip(-2000, 2000)\n",
    "# preprocess_df = preprocess_df.with_columns(expression)\n",
    "\n",
    "conditions = (\n",
    "    polars.when(polars.col(score_column) >= 0).then(1)\n",
    "    .when((polars.col(score_column) < 0)).then(0)\n",
    ")\n",
    "# Ajouter la colonne de classification au DataFrame\n",
    "preprocess_df = preprocess_df.with_columns(conditions.alias(\"classification\"))\n",
    "\n",
    "# Renomme les colonnes en 'fen' et 'score'\n",
    "preprocess_df = preprocess_df.rename({fen_column: 'fen', score_column: 'score'})"
   ],
   "id": "a6cb2b783923870a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value : '-7918.00  -  Max value : 6233.00\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T08:31:07.497793Z",
     "start_time": "2024-06-22T08:31:07.493476Z"
    }
   },
   "cell_type": "code",
   "source": "print(preprocess_df.head())",
   "id": "5c39ebc52ff375a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌────────────────┬───────┬────────────────┐\n",
      "│ fen            ┆ score ┆ classification │\n",
      "│ ---            ┆ ---   ┆ ---            │\n",
      "│ list[u8]       ┆ i16   ┆ i32            │\n",
      "╞════════════════╪═══════╪════════════════╡\n",
      "│ [6, 12, … 12]  ┆ 57    ┆ 1              │\n",
      "│ [12, 12, … 12] ┆ 82    ┆ 1              │\n",
      "│ [6, 12, … 12]  ┆ 116   ┆ 1              │\n",
      "│ [12, 12, … 12] ┆ -317  ┆ 0              │\n",
      "│ [12, 12, … 12] ┆ 46    ┆ 1              │\n",
      "└────────────────┴───────┴────────────────┘\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T08:31:07.505413Z",
     "start_time": "2024-06-22T08:31:07.498800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, preprocess_df: polars.DataFrame):\n",
    "        self.dataframe = preprocess_df\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        # Récupère la FEN et le score\n",
    "        array = self.dataframe['fen'][index]\n",
    "        _classification = self.dataframe['classification'][index]\n",
    "        classification = [0 for i in range(2)]\n",
    "        classification[_classification] = 1\n",
    "\n",
    "        # Convertit le tableau numpy en tenseur PyTorch\n",
    "        tensor_array = torch.tensor(array, dtype=torch.float32)\n",
    "        tensor_classification = torch.tensor(classification, dtype=torch.float32)\n",
    "\n",
    "        return tensor_array, tensor_classification\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def hist_score(self, bins: int = 51):\n",
    "        \"\"\"\n",
    "        Affiche un histogramme de la colonne 'score'.\n",
    "\n",
    "        Notes:\n",
    "            Incrémente bins de 1 si celui-ci est pair, cela permet d'afficher le nombre de\n",
    "            zeros dans la colonne 'score'. En impair, nous n'avons que pour > 0 ou < 0.\n",
    "\n",
    "        Args:\n",
    "            bins (int): Nombre de \"bacs\" pour l'histogramme. Defaults to 51.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Si le nombre de bacs est pair, on l'incrémente de 1\n",
    "        bins = bins + 1 if bins % 2 == 0 else bins\n",
    "\n",
    "        # Créer un histogramme de la colonne 'score'\n",
    "        plt.hist(self.dataframe['classification'], bins=bins)\n",
    "\n",
    "        # Ajouter des étiquettes et un titre\n",
    "        plt.xlabel('Valeur')\n",
    "        plt.ylabel('Fréquence')\n",
    "        plt.title('Distribution de la colonne \"score\"')\n",
    "\n",
    "        # Afficher le graphique\n",
    "        plt.show()"
   ],
   "id": "e83da124cbb95bc5",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T08:31:07.512675Z",
     "start_time": "2024-06-22T08:31:07.506423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.nn.functional import log_softmax\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class ChessModel(nn.Module):\n",
    "    def __init__(self, vocab_size: int = 13):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, 2048)\n",
    "        self.linear_1 = nn.Linear(2048, 1024)\n",
    "        self.linear_2 = nn.Linear(1024, 512)\n",
    "        self.linear_3 = nn.Linear(512, 2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        _x = self.embeddings(x.long())\n",
    "        _x = _x.sum(dim=1)\n",
    "        _x = self.linear_1(_x)\n",
    "        _x = self.linear_2(_x)\n",
    "        _x = self.linear_3(_x)\n",
    "        _x = log_softmax(_x, dim=1)\n",
    "        return _x\n",
    "\n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        return next(self.parameters()).device"
   ],
   "id": "2be33ecd57a472cc",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T08:31:07.752861Z",
     "start_time": "2024-06-22T08:31:07.513697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = ChessModel()\n",
    "dataset = ChessDataset(preprocess_df=preprocess_df)\n",
    "dataset.hist_score(bins=201)\n",
    "print(preprocess_df.get_column('classification').value_counts().sort(\"count\"))"
   ],
   "id": "24e3abe06562d7aa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 2)\n",
      "┌────────────────┬───────┐\n",
      "│ classification ┆ count │\n",
      "│ ---            ┆ ---   │\n",
      "│ i32            ┆ u32   │\n",
      "╞════════════════╪═══════╡\n",
      "│ 0              ┆ 362   │\n",
      "│ 1              ┆ 548   │\n",
      "└────────────────┴───────┘\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T08:31:08.636017Z",
     "start_time": "2024-06-22T08:31:07.753868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "import statistics\n",
    "from typing import Literal, Type\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import LRScheduler, LinearLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Metric, MeanAbsoluteError\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src import MODEL_PATH\n",
    "\n",
    "\n",
    "def train_model(\n",
    "        model: nn.Module,\n",
    "\n",
    "        train_loader: DataLoader,\n",
    "        tests_loader: DataLoader,\n",
    "        validation_loader: DataLoader,\n",
    "\n",
    "        num_epochs: int = 20,\n",
    "        device: Literal['cuda', 'cuda'] = 'cuda',\n",
    "\n",
    "        optimizer: Type[Optimizer] = torch.optim.Adam,\n",
    "        metric: Metric = MeanAbsoluteError,\n",
    "        criterion: _Loss = nn.MSELoss,\n",
    "\n",
    "        lr: float = 1e-4,\n",
    "\n",
    "        scheduler: Type[LRScheduler] = LinearLR,\n",
    "        start_factor: float = 1.0,\n",
    "        end_factor: float = 1e-6,\n",
    "        total_iters: int = 10\n",
    "):\n",
    "    train_score, tests_score, validation_score = 0, 0, 0\n",
    "\n",
    "    # Crée le modèle\n",
    "    model = model.to(device)\n",
    "    logging.info(f\"Device: {model.device}\")\n",
    "\n",
    "    # noinspection PyArgumentList\n",
    "    optimizer = optimizer(model.parameters(), lr=lr)\n",
    "\n",
    "    # noinspection PyArgumentList\n",
    "    scheduler = scheduler(\n",
    "        optimizer=optimizer,\n",
    "        start_factor=start_factor,\n",
    "        end_factor=end_factor,\n",
    "        total_iters=total_iters\n",
    "    )\n",
    "\n",
    "    metric_name = metric.__class__.__name__\n",
    "\n",
    "    # Entraîne le modèle\n",
    "    for epoch in range(num_epochs):\n",
    "        pbar = tqdm(train_loader, total=len(train_loader), leave=False)\n",
    "\n",
    "        list_loss = []\n",
    "        for x, y in pbar:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)  # Met 'y' en batch_size de 1\n",
    "\n",
    "            predictions = model(x).to(device=device)\n",
    "            # print(x.shape, y.shape, predictions.shape)\n",
    "            loss = criterion(predictions, y).to(device=device)\n",
    "            # raise Exception()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.set_description(f\"Epochs: {epoch + 1}/{num_epochs}  -  Loss: {loss.item():.1e}\")\n",
    "            list_loss.append(loss.item())\n",
    "\n",
    "        scheduler.step()\n",
    "        # afficher sous forme 1e-3, 2e-3, 3e-3, etc.\n",
    "        tqdm.write(f\"Learning rate: {scheduler.get_last_lr()[0]:.1e}\")\n",
    "        train_score = check_accuracy(train_loader, model, metric)\n",
    "        tests_score = check_accuracy(tests_loader, model, metric)\n",
    "\n",
    "        avg_loss = statistics.mean(list_loss)\n",
    "        tqdm.write(f\"Epochs: {epoch + 1}/{num_epochs}  -  Loss: {avg_loss:.1e}  -  Train ({metric_name}): {train_score:.2f}  -  Tests ({metric_name}) : {tests_score:.2f}\")\n",
    "\n",
    "        # Sauvegarde le modèle\n",
    "        path = MODEL_PATH / f\"model_{epoch + 1}.pth\"\n",
    "        torch.save(model.state_dict(), path)\n",
    "\n",
    "    # Affiche les derniers scores sur tout le dataset (tout les batchs)\n",
    "    validation_score = check_accuracy(validation_loader, model, metric)\n",
    "\n",
    "    logging.info(f\"[Score global train] : {train_score:.2f}%\")\n",
    "    logging.info(f\"[Score global tests] : {tests_score:.2f}%\")\n",
    "    logging.info(f\"[Score global validation] : {validation_score:.2f}%\")\n",
    "\n",
    "\n",
    "def check_accuracy(\n",
    "        loader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        metrics: Metric,\n",
    "):\n",
    "    \"\"\"\n",
    "    Fonction pour calculer la précision du modèle\n",
    "    \"\"\"\n",
    "    list_accuracy = []\n",
    "\n",
    "    # Récupère le device du modèle\n",
    "    device = model.device\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)  # Met 'y' en batch_size de 1\n",
    "\n",
    "            predictions = model(x).to(device=device)\n",
    "\n",
    "            accuracy = metrics(preds=predictions, target=y)\n",
    "            list_accuracy.append(accuracy.item())\n",
    "\n",
    "    global_accuracy = statistics.mean(list_accuracy)\n",
    "    return global_accuracy\n"
   ],
   "id": "17ac2e2e1bf3ddd3",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T08:31:14.203224Z",
     "start_time": "2024-06-22T08:31:08.638265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchmetrics.classification import BinaryAccuracy\n",
    "import os\n",
    "\n",
    "import torchmetrics\n",
    "from typing import Literal\n",
    "from src.dataset import split_dataset\n",
    "\n",
    "# Autres paramètres\n",
    "device: Literal['cuda', 'cuda'] = 'cuda'\n",
    "\n",
    "# Paramètres du dataset\n",
    "batch_size: int = 256\n",
    "random_seed: int = 42\n",
    "ratio_tests: float = 0.2\n",
    "ratio_validation: float = 0.2\n",
    "\n",
    "# Paramètres du modèle (apprentissage)\n",
    "num_epochs: int = 100\n",
    "lr: float = 1e-3\n",
    "\n",
    "# Paramètres du scheduler_lr (apprentissage)\n",
    "start_factor: float = 1.0\n",
    "end_factor: float = 0.01\n",
    "total_iters: int = 0\n",
    "\n",
    "metric = BinaryAccuracy().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "list_loaders = split_dataset(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle_dataset=False,\n",
    "    random_seed=random_seed,\n",
    "    ratio_tests=ratio_tests,\n",
    "    ratio_validation=ratio_validation\n",
    ")\n",
    "\n",
    "train_loader, tests_loader, validation_loader = list_loaders\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "train_model(\n",
    "    device=device,\n",
    "\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    tests_loader=tests_loader,\n",
    "    validation_loader=validation_loader,\n",
    "\n",
    "    num_epochs=num_epochs,\n",
    "    lr=lr,\n",
    "\n",
    "    start_factor=start_factor,\n",
    "    end_factor=end_factor,\n",
    "    total_iters=total_iters,\n",
    "\n",
    "    metric=metric,\n",
    "    criterion=criterion,\n",
    ")"
   ],
   "id": "b0199cdda968b447",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-03\n",
      "Epochs: 1/100  -  Loss: 2.8e+02  -  Train (BinaryAccuracy): 0.50  -  Tests (BinaryAccuracy) : 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-03\n",
      "Epochs: 2/100  -  Loss: 2.0e+02  -  Train (BinaryAccuracy): 0.50  -  Tests (BinaryAccuracy) : 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-03\n",
      "Epochs: 3/100  -  Loss: 1.3e+02  -  Train (BinaryAccuracy): 0.50  -  Tests (BinaryAccuracy) : 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-03\n",
      "Epochs: 4/100  -  Loss: 5.5e+01  -  Train (BinaryAccuracy): 0.50  -  Tests (BinaryAccuracy) : 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-03\n",
      "Epochs: 5/100  -  Loss: 8.6e+01  -  Train (BinaryAccuracy): 0.50  -  Tests (BinaryAccuracy) : 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-03\n",
      "Epochs: 6/100  -  Loss: 1.3e+02  -  Train (BinaryAccuracy): 0.50  -  Tests (BinaryAccuracy) : 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7/100  -  Loss: 5.2e+01  -  Train (BinaryAccuracy): 0.50  -  Tests (BinaryAccuracy) : 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-03\n",
      "Epochs: 8/100  -  Loss: 5.5e+01  -  Train (BinaryAccuracy): 0.50  -  Tests (BinaryAccuracy) : 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9/100  -  Loss: 6.3e+01  -  Train (BinaryAccuracy): 0.50  -  Tests (BinaryAccuracy) : 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-03\n",
      "Epochs: 10/100  -  Loss: 2.4e+01  -  Train (BinaryAccuracy): 0.50  -  Tests (BinaryAccuracy) : 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-03\n",
      "Epochs: 11/100  -  Loss: 1.4e+01  -  Train (BinaryAccuracy): 0.50  -  Tests (BinaryAccuracy) : 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-03\n",
      "Epochs: 12/100  -  Loss: 1.1e+01  -  Train (BinaryAccuracy): 0.50  -  Tests (BinaryAccuracy) : 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-03\n",
      "Epochs: 13/100  -  Loss: 1.2e+01  -  Train (BinaryAccuracy): 0.50  -  Tests (BinaryAccuracy) : 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-03\n",
      "Epochs: 14/100  -  Loss: 6.6e+00  -  Train (BinaryAccuracy): 0.50  -  Tests (BinaryAccuracy) : 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-03\n",
      "Epochs: 15/100  -  Loss: 9.3e+00  -  Train (BinaryAccuracy): 0.50  -  Tests (BinaryAccuracy) : 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-03\n",
      "Epochs: 16/100  -  Loss: 3.4e+00  -  Train (BinaryAccuracy): 0.50  -  Tests (BinaryAccuracy) : 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-03\n",
      "Epochs: 17/100  -  Loss: 2.6e+00  -  Train (BinaryAccuracy): 0.50  -  Tests (BinaryAccuracy) : 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-03\n",
      "Epochs: 18/100  -  Loss: 3.2e+00  -  Train (BinaryAccuracy): 0.50  -  Tests (BinaryAccuracy) : 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-03\n",
      "Epochs: 19/100  -  Loss: 1.4e+00  -  Train (BinaryAccuracy): 0.50  -  Tests (BinaryAccuracy) : 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-03\n",
      "Epochs: 20/100  -  Loss: 1.7e+00  -  Train (BinaryAccuracy): 0.50  -  Tests (BinaryAccuracy) : 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-03\n",
      "Epochs: 21/100  -  Loss: 1.0e+00  -  Train (BinaryAccuracy): 0.50  -  Tests (BinaryAccuracy) : 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.0e-03\n",
      "Epochs: 22/100  -  Loss: 1.0e+00  -  Train (BinaryAccuracy): 0.50  -  Tests (BinaryAccuracy) : 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                     \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 46\u001B[0m\n\u001B[0;32m     41\u001B[0m gc\u001B[38;5;241m.\u001B[39mcollect()\n\u001B[0;32m     43\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 46\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     47\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     48\u001B[0m \n\u001B[0;32m     49\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     50\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     51\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtests_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtests_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     52\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     53\u001B[0m \n\u001B[0;32m     54\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     56\u001B[0m \n\u001B[0;32m     57\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstart_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstart_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     58\u001B[0m \u001B[43m    \u001B[49m\u001B[43mend_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mend_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     59\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtotal_iters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_iters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     60\u001B[0m \n\u001B[0;32m     61\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     62\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     63\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[18], line 62\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, train_loader, tests_loader, validation_loader, num_epochs, device, optimizer, metric, criterion, lr, scheduler, start_factor, end_factor, total_iters)\u001B[0m\n\u001B[0;32m     59\u001B[0m pbar \u001B[38;5;241m=\u001B[39m tqdm(train_loader, total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(train_loader), leave\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m     61\u001B[0m list_loss \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m---> 62\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpbar\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m     63\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     64\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Met 'y' en batch_size de 1\u001B[39;49;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\chess_pytorch_ai\\Lib\\site-packages\\tqdm\\std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1181\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m   1182\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\n\u001B[0;32m   1183\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Update and possibly print the progressbar.\u001B[39;49;00m\n\u001B[0;32m   1184\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;49;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\chess_pytorch_ai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\chess_pytorch_ai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\chess_pytorch_ai\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[1;32m---> 54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\chess_pytorch_ai\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:316\u001B[0m, in \u001B[0;36mdefault_collate\u001B[1;34m(batch)\u001B[0m\n\u001B[0;32m    255\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_collate\u001B[39m(batch):\n\u001B[0;32m    256\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    257\u001B[0m \u001B[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001B[39;00m\n\u001B[0;32m    258\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    314\u001B[0m \u001B[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001B[39;00m\n\u001B[0;32m    315\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 316\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_collate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\chess_pytorch_ai\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:173\u001B[0m, in \u001B[0;36mcollate\u001B[1;34m(batch, collate_fn_map)\u001B[0m\n\u001B[0;32m    170\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m--> 173\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m[\u001B[49m\u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msamples\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtransposed\u001B[49m\u001B[43m]\u001B[49m  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[0;32m    174\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    175\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\chess_pytorch_ai\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:173\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    170\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m--> 173\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[0;32m    174\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    175\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\chess_pytorch_ai\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:141\u001B[0m, in \u001B[0;36mcollate\u001B[1;34m(batch, collate_fn_map)\u001B[0m\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m collate_fn_map \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    140\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m elem_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[1;32m--> 141\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate_fn_map\u001B[49m\u001B[43m[\u001B[49m\u001B[43melem_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    143\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m collate_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[0;32m    144\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, collate_type):\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\chess_pytorch_ai\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:213\u001B[0m, in \u001B[0;36mcollate_tensor_fn\u001B[1;34m(batch, collate_fn_map)\u001B[0m\n\u001B[0;32m    211\u001B[0m     storage \u001B[38;5;241m=\u001B[39m elem\u001B[38;5;241m.\u001B[39m_typed_storage()\u001B[38;5;241m.\u001B[39m_new_shared(numel, device\u001B[38;5;241m=\u001B[39melem\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m    212\u001B[0m     out \u001B[38;5;241m=\u001B[39m elem\u001B[38;5;241m.\u001B[39mnew(storage)\u001B[38;5;241m.\u001B[39mresize_(\u001B[38;5;28mlen\u001B[39m(batch), \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlist\u001B[39m(elem\u001B[38;5;241m.\u001B[39msize()))\n\u001B[1;32m--> 213\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T08:31:24.027459Z",
     "start_time": "2024-06-22T08:31:23.733842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src import MODEL_PATH\n",
    "\n",
    "path = MODEL_PATH / 'model_23.pth'\n",
    "dict_model = torch.load(path, map_location='cuda')\n",
    "model = ChessModel().to(device)\n",
    "model.load_state_dict(dict_model)\n",
    "\n",
    "\n",
    "def analys_model(fen: str):\n",
    "    fen_array = tokenize_fen(fen)\n",
    "    fen_tensor = torch.tensor(fen_array, dtype=torch.float32).view(1, -1).to(device)\n",
    "    prediction = model(fen_tensor).argmax().item()\n",
    "\n",
    "    print(f\"Prédiction du modèle: {prediction:.2f}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "list_fen = [\n",
    "    \"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\",  # Position de base\n",
    "    \"r1bqkb1r/pppp1ppp/2n2n2/4p2Q/2B1P3/8/PPPP1PPP/RNB1K1NR w KQkq - 4 4\",  # Mat berger, Mat en 1 pour blanc\n",
    "    \"4k3/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQ - 0 1\",  # Noir n'ont qu'un roi\n",
    "    \"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/4K3 w kq - 0 1\",  # Blanc n'ont qu'un roi\n",
    "    \"r3rbk1/p4ppp/8/2Nqp3/1p1P2b1/1P3N2/P2P1PPP/2RQR1K1 w - - 1 21\"  # Position égale éloignée GMI (reputé légèrement favorable noir)\n",
    "]\n",
    "\n",
    "for fen in list_fen:\n",
    "    analys_model(fen)"
   ],
   "id": "576ca51824bc377d",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ChessModel:\n\tUnexpected key(s) in state_dict: \"batch_norm_1.weight\", \"batch_norm_1.bias\", \"batch_norm_1.running_mean\", \"batch_norm_1.running_var\", \"batch_norm_1.num_batches_tracked\", \"batch_norm_2.weight\", \"batch_norm_2.bias\", \"batch_norm_2.running_mean\", \"batch_norm_2.running_var\", \"batch_norm_2.num_batches_tracked\", \"batch_norm_3.weight\", \"batch_norm_3.bias\", \"batch_norm_3.running_mean\", \"batch_norm_3.running_var\", \"batch_norm_3.num_batches_tracked\", \"linear_4.weight\", \"linear_4.bias\". \n\tsize mismatch for linear_3.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([2, 512]).\n\tsize mismatch for linear_3.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([2]).",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m dict_model \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mload(path, map_location\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m model \u001B[38;5;241m=\u001B[39m ChessModel()\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m----> 6\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_state_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdict_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21manalys_model\u001B[39m(fen: \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m     10\u001B[0m     fen_array \u001B[38;5;241m=\u001B[39m tokenize_fen(fen)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\chess_pytorch_ai\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2189\u001B[0m, in \u001B[0;36mModule.load_state_dict\u001B[1;34m(self, state_dict, strict, assign)\u001B[0m\n\u001B[0;32m   2184\u001B[0m         error_msgs\u001B[38;5;241m.\u001B[39minsert(\n\u001B[0;32m   2185\u001B[0m             \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMissing key(s) in state_dict: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   2186\u001B[0m                 \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m missing_keys)))\n\u001B[0;32m   2188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(error_msgs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m-> 2189\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mError(s) in loading state_dict for \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   2190\u001B[0m                        \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(error_msgs)))\n\u001B[0;32m   2191\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Error(s) in loading state_dict for ChessModel:\n\tUnexpected key(s) in state_dict: \"batch_norm_1.weight\", \"batch_norm_1.bias\", \"batch_norm_1.running_mean\", \"batch_norm_1.running_var\", \"batch_norm_1.num_batches_tracked\", \"batch_norm_2.weight\", \"batch_norm_2.bias\", \"batch_norm_2.running_mean\", \"batch_norm_2.running_var\", \"batch_norm_2.num_batches_tracked\", \"batch_norm_3.weight\", \"batch_norm_3.bias\", \"batch_norm_3.running_mean\", \"batch_norm_3.running_var\", \"batch_norm_3.num_batches_tracked\", \"linear_4.weight\", \"linear_4.bias\". \n\tsize mismatch for linear_3.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([2, 512]).\n\tsize mismatch for linear_3.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([2])."
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "54f2a2c5b1a8e145",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
