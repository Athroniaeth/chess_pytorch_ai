{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-21T20:46:00.896401Z",
     "start_time": "2024-06-21T20:46:00.357011Z"
    }
   },
   "source": [
    "import polars\n",
    "\n",
    "max_length = 20_000\n",
    "dataframe = polars.read_csv('../data/chessData.csv')\n",
    "dataframe = dataframe.sample(shuffle=True, seed=42, n=max_length)\n",
    "print(dataframe.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 2)\n",
      "┌─────────────────────────────────┬────────────┐\n",
      "│ FEN                             ┆ Evaluation │\n",
      "│ ---                             ┆ ---        │\n",
      "│ str                             ┆ str        │\n",
      "╞═════════════════════════════════╪════════════╡\n",
      "│ r1bq2k1/1p3pbp/p2p1np1/2pPr3/P… ┆ +57        │\n",
      "│ R5k1/2nbqpp1/3b1n1p/2pPp3/2P1P… ┆ +82        │\n",
      "│ rqr3k1/3npp2/3p2p1/1N1P3p/P1pR… ┆ +116       │\n",
      "│ 8/5pp1/k5p1/1pK5/8/7P/5PP1/8 w… ┆ -317       │\n",
      "│ 3r2k1/5p1p/1RN1p3/5nP1/1p6/2b1… ┆ +46        │\n",
      "└─────────────────────────────────┴────────────┘\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T20:46:00.903030Z",
     "start_time": "2024-06-21T20:46:00.897913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy\n",
    "from typing import Generator, Tuple\n",
    "import itertools\n",
    "import chess\n",
    "\n",
    "ProductPiece = Tuple[chess.PieceType, chess.Color]\n",
    "\n",
    "\n",
    "def generator_pieces() -> Generator[ProductPiece, None, None]:\n",
    "    return itertools.product(chess.PIECE_TYPES, chess.COLORS)\n",
    "\n",
    "\n",
    "def tokenize_fen(fen: str):\n",
    "    board = chess.Board(fen=fen)\n",
    "    board_array = numpy.array([], ndmin=2)\n",
    "\n",
    "    for piece_type, color in generator_pieces():\n",
    "        # Obtiens les pièces du plateau\n",
    "        square_set = board.pieces(piece_type, color)\n",
    "\n",
    "        # Crée un masque (numpy va inverser les axes, donc on utilise mirror)\n",
    "        mask = square_set.mirror().tolist()\n",
    "\n",
    "        # Convertit le masque en tableau numpy et en one-hot\n",
    "        piece_array = numpy.array(mask).astype(int)\n",
    "\n",
    "        # Ajoute le tableau de pièces au tableau de plateau\n",
    "        board_array = numpy.append(board_array, piece_array)\n",
    "    \n",
    "    # reshape (768,) to (12, 64,)\n",
    "    board_array = board_array.reshape(12, 64)\n",
    "    board_array = board_array.astype(numpy.uint8)\n",
    "    return tuple(board_array)"
   ],
   "id": "bfdafbaf4a4a24fd",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T20:46:00.910100Z",
     "start_time": "2024-06-21T20:46:00.904042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_pos = \"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\"\n",
    "result = tokenize_fen(start_pos)\n",
    "print(len(result))\n",
    "print(sum(result))\n",
    "\n",
    "print(sum(result[:64]))  # white pawn\n",
    "print(sum(result[64:128]))  # black pawn\n",
    "\n",
    "print(sum(result[-128:-64]))  # white king\n",
    "print(sum(result[-64:]))  # black king"
   ],
   "id": "756c366ced9e6cea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "0\n",
      "0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T20:46:06.069608Z",
     "start_time": "2024-06-21T20:46:00.911648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from polars import List, UInt8\n",
    "\n",
    "fen_column = \"FEN\"\n",
    "score_column = \"Evaluation\"\n",
    "\n",
    "expression = polars.col(fen_column).map_elements(tokenize_fen, return_dtype=polars.List(List(UInt8)))\n",
    "preprocess_df = dataframe.with_columns(expression)\n",
    "\n",
    "# Renomme les colonnes en 'fen' et 'score'\n",
    "preprocess_df = preprocess_df.rename({fen_column: 'fen', score_column: 'score'})\n",
    "\n",
    "print(preprocess_df.head())\n",
    "\n",
    "# Explode the 'fen' column to create new rows\n",
    "preprocess_df = preprocess_df.explode('fen')\n",
    "\n",
    "print(preprocess_df.head())"
   ],
   "id": "a6cb2b783923870a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 2)\n",
      "┌─────────────────────────────────┬───────┐\n",
      "│ fen                             ┆ score │\n",
      "│ ---                             ┆ ---   │\n",
      "│ list[list[u8]]                  ┆ str   │\n",
      "╞═════════════════════════════════╪═══════╡\n",
      "│ [[0, 0, … 0], [0, 0, … 0], … [… ┆ +57   │\n",
      "│ [[0, 0, … 0], [0, 0, … 0], … [… ┆ +82   │\n",
      "│ [[0, 0, … 0], [0, 0, … 0], … [… ┆ +116  │\n",
      "│ [[0, 0, … 0], [0, 0, … 0], … [… ┆ -317  │\n",
      "│ [[0, 0, … 0], [0, 0, … 0], … [… ┆ +46   │\n",
      "└─────────────────────────────────┴───────┘\n",
      "shape: (5, 2)\n",
      "┌─────────────┬───────┐\n",
      "│ fen         ┆ score │\n",
      "│ ---         ┆ ---   │\n",
      "│ list[u8]    ┆ str   │\n",
      "╞═════════════╪═══════╡\n",
      "│ [0, 0, … 0] ┆ +57   │\n",
      "│ [0, 0, … 0] ┆ +57   │\n",
      "│ [0, 0, … 0] ┆ +57   │\n",
      "│ [0, 0, … 0] ┆ +57   │\n",
      "│ [0, 0, … 0] ┆ +57   │\n",
      "└─────────────┴───────┘\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T20:46:06.074651Z",
     "start_time": "2024-06-21T20:46:06.069608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(preprocess_df.head())\n",
    "print(preprocess_df.tail())"
   ],
   "id": "5c39ebc52ff375a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 2)\n",
      "┌─────────────┬───────┐\n",
      "│ fen         ┆ score │\n",
      "│ ---         ┆ ---   │\n",
      "│ list[u8]    ┆ str   │\n",
      "╞═════════════╪═══════╡\n",
      "│ [0, 0, … 0] ┆ +57   │\n",
      "│ [0, 0, … 0] ┆ +57   │\n",
      "│ [0, 0, … 0] ┆ +57   │\n",
      "│ [0, 0, … 0] ┆ +57   │\n",
      "│ [0, 0, … 0] ┆ +57   │\n",
      "└─────────────┴───────┘\n",
      "shape: (5, 2)\n",
      "┌─────────────┬───────┐\n",
      "│ fen         ┆ score │\n",
      "│ ---         ┆ ---   │\n",
      "│ list[u8]    ┆ str   │\n",
      "╞═════════════╪═══════╡\n",
      "│ [0, 0, … 0] ┆ +184  │\n",
      "│ [0, 0, … 0] ┆ +184  │\n",
      "│ [0, 0, … 0] ┆ +184  │\n",
      "│ [0, 0, … 0] ┆ +184  │\n",
      "│ [0, 0, … 0] ┆ +184  │\n",
      "└─────────────┴───────┘\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T20:46:06.086906Z",
     "start_time": "2024-06-21T20:46:06.075173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, preprocess_df: polars.DataFrame):\n",
    "        self.dataframe = preprocess_df\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        # Récupère la FEN et le score\n",
    "        array = self.dataframe['fen'][index]\n",
    "\n",
    "        # Convertit le tableau numpy en tenseur PyTorch\n",
    "        tensor_array = torch.tensor(array, dtype=torch.float32)\n",
    "\n",
    "        return tensor_array, tensor_array\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)"
   ],
   "id": "e83da124cbb95bc5",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T20:46:06.093470Z",
     "start_time": "2024-06-21T20:46:06.087914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class ChessModel(nn.Module):\n",
    "    def __init__(self, input_dim=64, latent_dim=32):\n",
    "        super(ChessModel, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, latent_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        return next(self.parameters()).device\n"
   ],
   "id": "2be33ecd57a472cc",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T20:46:06.103453Z",
     "start_time": "2024-06-21T20:46:06.094843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = ChessModel()\n",
    "dataset = ChessDataset(preprocess_df=preprocess_df)"
   ],
   "id": "24e3abe06562d7aa",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T20:46:06.117958Z",
     "start_time": "2024-06-21T20:46:06.104461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "import statistics\n",
    "from typing import Literal, Type\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import LRScheduler, LinearLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Metric, MeanAbsoluteError\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src import MODEL_PATH\n",
    "\n",
    "\n",
    "def train_model(\n",
    "        model: nn.Module,\n",
    "\n",
    "        train_loader: DataLoader,\n",
    "        tests_loader: DataLoader,\n",
    "        validation_loader: DataLoader,\n",
    "\n",
    "        num_epochs: int = 20,\n",
    "        device: Literal['cpu', 'cuda'] = 'cuda',\n",
    "\n",
    "        optimizer: Type[Optimizer] = torch.optim.Adam,\n",
    "        metric: Metric = MeanAbsoluteError,\n",
    "        criterion: _Loss = nn.MSELoss,\n",
    "\n",
    "        lr: float = 1e-4,\n",
    "\n",
    "        scheduler: Type[LRScheduler] = LinearLR,\n",
    "        start_factor: float = 1.0,\n",
    "        end_factor: float = 1e-6,\n",
    "        total_iters: int = 10\n",
    "):\n",
    "    train_score, tests_score, validation_score = 0, 0, 0\n",
    "\n",
    "    # Crée le modèle\n",
    "    model = model.to(device)\n",
    "    logging.info(f\"Device: {model.device}\")\n",
    "\n",
    "    # noinspection PyArgumentList\n",
    "    optimizer = optimizer(model.parameters(), lr=lr)\n",
    "\n",
    "    # noinspection PyArgumentList\n",
    "    scheduler = scheduler(\n",
    "        optimizer=optimizer,\n",
    "        start_factor=start_factor,\n",
    "        end_factor=end_factor,\n",
    "        total_iters=total_iters\n",
    "    )\n",
    "\n",
    "    metric_name = metric.__class__.__name__\n",
    "\n",
    "    # Entraîne le modèle\n",
    "    for epoch in range(num_epochs):\n",
    "        pbar = tqdm(train_loader, total=len(train_loader), leave=False)\n",
    "\n",
    "        list_loss = []\n",
    "        list_loss.clear()\n",
    "        for x, y in pbar:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)  # Met 'y' en batch_size de 1\n",
    "\n",
    "            predictions = model(x).round().to(device=device)\n",
    "\n",
    "            loss = criterion(predictions, target=y).to(device=device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.set_description(f\"Epochs: {epoch + 1}/{num_epochs}  -  Loss: {loss.item():.1e}\")\n",
    "            list_loss.append(loss.item())\n",
    "\n",
    "        scheduler.step()\n",
    "        # afficher sous forme 1e-3, 2e-3, 3e-3, etc.\n",
    "        tqdm.write(f\"Learning rate: {scheduler.get_last_lr()[0]:.1e}\")\n",
    "        train_score = check_accuracy(train_loader, model, metric)\n",
    "        tests_score = check_accuracy(tests_loader, model, metric)\n",
    "\n",
    "        avg_loss = statistics.mean(list_loss)\n",
    "        tqdm.write(f\"Epochs: {epoch + 1}/{num_epochs}  -  Loss: {avg_loss:.1e}  -  Train ({metric_name}): {train_score:.2f}  -  Tests ({metric_name}) : {tests_score:.2f}\")\n",
    "\n",
    "        # Sauvegarde le modèle\n",
    "        path = MODEL_PATH / f\"model_{epoch + 1}.pth\"\n",
    "        torch.save(model.state_dict(), path)\n",
    "\n",
    "    # Affiche les derniers scores sur tout le dataset (tout les batchs)\n",
    "    validation_score = check_accuracy(validation_loader, model, metric)\n",
    "\n",
    "    logging.info(f\"[Score global train] : {train_score:.2f}%\")\n",
    "    logging.info(f\"[Score global tests] : {tests_score:.2f}%\")\n",
    "    logging.info(f\"[Score global validation] : {validation_score:.2f}%\")\n",
    "\n",
    "\n",
    "def check_accuracy(\n",
    "        loader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        metrics: Metric,\n",
    "):\n",
    "    \"\"\"\n",
    "    Fonction pour calculer la précision du modèle\n",
    "    \"\"\"\n",
    "    list_accuracy = []\n",
    "\n",
    "    # Récupère le device du modèle\n",
    "    device = model.device\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)  # Met 'y' en batch_size de 1\n",
    "\n",
    "            predictions = model(x).round().to(device=device)\n",
    "\n",
    "            accuracy = metrics(preds=predictions, target=y)\n",
    "            list_accuracy.append(accuracy.item())\n",
    "\n",
    "    global_accuracy = statistics.mean(list_accuracy)\n",
    "    return global_accuracy\n"
   ],
   "id": "17ac2e2e1bf3ddd3",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T20:56:14.777614Z",
     "start_time": "2024-06-21T20:49:07.088090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import torchmetrics\n",
    "from typing import Literal\n",
    "from src.dataset import split_dataset\n",
    "\n",
    "# Autres paramètres\n",
    "device = 'cuda'\n",
    "\n",
    "# Paramètres du dataset\n",
    "batch_size: int = 64\n",
    "random_seed: int = 42\n",
    "ratio_tests: float = 0.2\n",
    "ratio_validation: float = 0.2\n",
    "\n",
    "# Paramètres du modèle (apprentissage)\n",
    "num_epochs: int = 100\n",
    "lr: float = 1e-2\n",
    "\n",
    "# Paramètres du scheduler_lr (apprentissage)\n",
    "start_factor: float = 1.0\n",
    "end_factor: float = 0.01\n",
    "total_iters: int = 20\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "metric = torchmetrics.MeanSquaredError().to(device)\n",
    "\n",
    "list_loaders = split_dataset(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle_dataset=False,\n",
    "    random_seed=random_seed,\n",
    "    ratio_tests=ratio_tests,\n",
    "    ratio_validation=ratio_validation\n",
    ")\n",
    "\n",
    "train_loader, tests_loader, validation_loader = list_loaders\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "train_model(\n",
    "    device=device,\n",
    "\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    tests_loader=tests_loader,\n",
    "    validation_loader=validation_loader,\n",
    "\n",
    "    num_epochs=num_epochs,\n",
    "    lr=lr,\n",
    "\n",
    "    start_factor=start_factor,\n",
    "    end_factor=end_factor,\n",
    "    total_iters=total_iters,\n",
    "\n",
    "    metric=metric,\n",
    "    criterion=criterion,\n",
    ")"
   ],
   "id": "b0199cdda968b447",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 9.5e-03\n",
      "Epochs: 1/100  -  Loss: 5.6e+01  -  Train (MeanSquaredError): 0.56  -  Tests (MeanSquaredError) : 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 9.0e-03\n",
      "Epochs: 2/100  -  Loss: 5.6e+01  -  Train (MeanSquaredError): 0.56  -  Tests (MeanSquaredError) : 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 8.5e-03\n",
      "Epochs: 3/100  -  Loss: 5.6e+01  -  Train (MeanSquaredError): 0.56  -  Tests (MeanSquaredError) : 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 8.0e-03\n",
      "Epochs: 4/100  -  Loss: 5.6e+01  -  Train (MeanSquaredError): 0.56  -  Tests (MeanSquaredError) : 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 7.5e-03\n",
      "Epochs: 5/100  -  Loss: 5.6e+01  -  Train (MeanSquaredError): 0.56  -  Tests (MeanSquaredError) : 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 7.0e-03\n",
      "Epochs: 6/100  -  Loss: 5.6e+01  -  Train (MeanSquaredError): 0.56  -  Tests (MeanSquaredError) : 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 6.5e-03\n",
      "Epochs: 7/100  -  Loss: 5.6e+01  -  Train (MeanSquaredError): 0.56  -  Tests (MeanSquaredError) : 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 6.0e-03\n",
      "Epochs: 8/100  -  Loss: 5.6e+01  -  Train (MeanSquaredError): 0.56  -  Tests (MeanSquaredError) : 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5.5e-03\n",
      "Epochs: 9/100  -  Loss: 5.6e+01  -  Train (MeanSquaredError): 0.56  -  Tests (MeanSquaredError) : 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 5.0e-03\n",
      "Epochs: 10/100  -  Loss: 5.6e+01  -  Train (MeanSquaredError): 0.56  -  Tests (MeanSquaredError) : 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 4.6e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x000002018BB72B90>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pierr\\miniconda3\\envs\\chess_pytorch_ai\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 11/100  -  Loss: 5.6e+01  -  Train (MeanSquaredError): 0.56  -  Tests (MeanSquaredError) : 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 4.1e-03\n",
      "Epochs: 12/100  -  Loss: 5.6e+01  -  Train (MeanSquaredError): 0.56  -  Tests (MeanSquaredError) : 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 47\u001B[0m\n\u001B[0;32m     43\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCUDA_LAUNCH_BLOCKING\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     44\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 47\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     48\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     49\u001B[0m \n\u001B[0;32m     50\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     51\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     52\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtests_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtests_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     54\u001B[0m \n\u001B[0;32m     55\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     57\u001B[0m \n\u001B[0;32m     58\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstart_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstart_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     59\u001B[0m \u001B[43m    \u001B[49m\u001B[43mend_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mend_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtotal_iters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_iters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     61\u001B[0m \n\u001B[0;32m     62\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     63\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     64\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[19], line 75\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, train_loader, tests_loader, validation_loader, num_epochs, device, optimizer, metric, criterion, lr, scheduler, start_factor, end_factor, total_iters)\u001B[0m\n\u001B[0;32m     72\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     73\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m---> 75\u001B[0m     pbar\u001B[38;5;241m.\u001B[39mset_description(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpochs: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m  -  Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.1e\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     76\u001B[0m     list_loss\u001B[38;5;241m.\u001B[39mappend(loss\u001B[38;5;241m.\u001B[39mitem())\n\u001B[0;32m     78\u001B[0m scheduler\u001B[38;5;241m.\u001B[39mstep()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T20:56:21.515465Z",
     "start_time": "2024-06-21T20:56:21.070484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src import MODEL_PATH\n",
    "\n",
    "path = MODEL_PATH / 'model_12.pth'\n",
    "dict_model = torch.load(path, map_location=device)\n",
    "model = ChessModel().to(device)\n",
    "model.load_state_dict(dict_model)\n",
    "\n",
    "\n",
    "def analys_model(fen: str):\n",
    "    fen_array = tokenize_fen(fen)\n",
    "    fen_tensor = torch.tensor(fen_array, dtype=torch.float32).to(device)\n",
    "    prediction = model(fen_tensor)\n",
    "    \n",
    "    print(fen_tensor.sum())\n",
    "    print(prediction.sum())\n",
    "    print(prediction.round())\n",
    "\n",
    "\n",
    "list_fen = [\n",
    "    \"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\",  # Position de base\n",
    "    \"r1bqkb1r/pppp1ppp/2n2n2/4p2Q/2B1P3/8/PPPP1PPP/RNB1K1NR w KQkq - 4 4\",  # Mat berger, Mat en 1 pour blanc\n",
    "    \"4k3/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQ - 0 1\",  # Noir n'ont qu'un roi\n",
    "    \"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/4K3 w kq - 0 1\",  # Blanc n'ont qu'un roi\n",
    "    \"r3rbk1/p4ppp/8/2Nqp3/1p1P2b1/1P3N2/P2P1PPP/2RQR1K1 w - - 1 21\"  # Position égale éloignée GMI (reputé légèrement favorable noir)\n",
    "]\n",
    "\n",
    "for fen in list_fen:\n",
    "    analys_model(fen)"
   ],
   "id": "576ca51824bc377d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pierr\\AppData\\Local\\Temp\\ipykernel_33328\\2340551914.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  fen_tensor = torch.tensor(fen_array, dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32., device='cuda:0')\n",
      "tensor(384.6473, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor([[0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.]], device='cuda:0',\n",
      "       grad_fn=<RoundBackward0>)\n",
      "tensor(32., device='cuda:0')\n",
      "tensor(384.6479, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor([[0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.]], device='cuda:0',\n",
      "       grad_fn=<RoundBackward0>)\n",
      "tensor(25., device='cuda:0')\n",
      "tensor(384.6415, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor([[0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.]], device='cuda:0',\n",
      "       grad_fn=<RoundBackward0>)\n",
      "tensor(25., device='cuda:0')\n",
      "tensor(384.6462, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor([[0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.]], device='cuda:0',\n",
      "       grad_fn=<RoundBackward0>)\n",
      "tensor(25., device='cuda:0')\n",
      "tensor(384.6548, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor([[0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 1., 1., 0.]], device='cuda:0',\n",
      "       grad_fn=<RoundBackward0>)\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "54f2a2c5b1a8e145",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
